{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Discriminant Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPORRdKXaIxsgmoHYr8ns+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romulan12/ML-algorithms/blob/master/Linear_Discriminant_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-AegfsGLE5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c5df7e9-3caa-4a7c-dd8f-b34b2e7976c4"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "def read_training_file(fname):\n",
        "    \"\"\"This function reads the training file line by line and creats the required lists, that is,\n",
        "the list of features for each class\"\"\"\n",
        "    temp_listx1 = []\n",
        "    temp_listx2 = []\n",
        "    temp_listx3 = []\n",
        "    total_len = c1 = c2 = c3 = 0    \n",
        "    with open(fname) as fl:\n",
        "        for line in fl:\n",
        "          try:\n",
        "            total_len+=1\n",
        "            seg = line.strip().split(',')            \n",
        "            if (seg[4] == 'Iris-setosa'):\n",
        "                c1+=1\n",
        "                temp_listx1.append([float(seg[0]),float(seg[1]),float(seg[2]),float(seg[3])])\n",
        "            elif (seg[4] == 'Iris-versicolor'):\n",
        "                c2+=1\n",
        "                temp_listx2.append([float(seg[0]),float(seg[1]),float(seg[2]),float(seg[3])])\n",
        "            else:\n",
        "                c3+=1\n",
        "                temp_listx3.append([float(seg[0]),float(seg[1]),float(seg[2]),float(seg[3])])\n",
        "          except IndexError:\n",
        "            pass\n",
        "        return (temp_listx1,temp_listx2,temp_listx3,c1,c2,c3,total_len)\n",
        "\n",
        "def read_testing_file(fname):\n",
        "    \"\"\"To read the validation file and return the set of lines in the file\"\"\"\n",
        "    return [line.strip().split(',') for line in open(fname).readlines()]\n",
        "     \n",
        "def lda(l,x1,x2,x3,c1,c2,c3,total_len):\n",
        "    \"\"\"This function implements the lda\"\"\"\n",
        "    t = [0,0,0,0]\n",
        "    x = [x1,x2,x3]\n",
        "    cm = 0    \n",
        "    class_mean = [[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0]]\n",
        "    \"\"\"Find the mean of each feature in the feature vector for each class\"\"\"\n",
        "    for a in x:\n",
        "        summ = [0.0,0.0,0.0,0.0]\n",
        "        avg = [0.0,0.0,0.0,0.0]\n",
        "        c = 0\n",
        "        for j in a:\n",
        "            c += 1\n",
        "            for k in range(4):\n",
        "                summ[k] = summ[k] + j[k]\n",
        "        for i in range(4):\n",
        "            avg[i] = summ[i]/float(c)\n",
        "        class_mean[cm] = avg\n",
        "        cm += 1\n",
        "    mean1 = np.matrix(class_mean[0])\n",
        "    mean2 = np.matrix(class_mean[1])\n",
        "    mean3 = np.matrix(class_mean[2])\n",
        "    \n",
        "    \n",
        "    \"\"\"Mean of all the features using the mean of the features of each class\"\"\"\n",
        "    for i in range(4):\n",
        "        for j in range(3):\n",
        "            t[i] += (class_mean[j][i])\n",
        "        t[i] /= 3.0\n",
        "    mean = np.matrix(t)\n",
        "\n",
        "    \"\"\"Computing difference of mean and each feature vector for class 1\"\"\"\n",
        "    c1_diff = []\n",
        "    for i in x1:\n",
        "        t = [0,0,0,0]\n",
        "        for j in range(4):\n",
        "            t[j] = i[j] - mean1.item(j)\n",
        "        c1_diff.append(t)\n",
        "    c1_diff_mat = np.matrix(c1_diff)\n",
        "    \n",
        "    \"\"\"Computing difference of mean and each feature vector for class 1\"\"\"\n",
        "    c2_diff = []\n",
        "    for i in x2:\n",
        "        t = [0,0,0,0]\n",
        "        for j in range(4):\n",
        "            t[j] = i[j] - mean2.item(j)\n",
        "        c2_diff.append(t)\n",
        "    c2_diff_mat = np.matrix(c2_diff)\n",
        "    \n",
        "    \"\"\"Computing difference of mean and each feature vector for class 1\"\"\"\n",
        "    c3_diff = []\n",
        "    for i in x3:\n",
        "        t = [0,0,0,0]\n",
        "        for j in range(4):\n",
        "            t[j] = i[j] - mean3.item(j)\n",
        "        c3_diff.append(t)\n",
        "    c3_diff_mat = np.matrix(c3_diff)\n",
        "    \n",
        "    \"\"\"Computing the individual covariance matrix\"\"\"\n",
        "    cc1 = c1_diff_mat.T * c1_diff_mat * (1.0/c1)\n",
        "    cc2 = c2_diff_mat.T * c2_diff_mat * (1.0/c2)\n",
        "    cc3 = c3_diff_mat.T * c3_diff_mat * (1.0/c3)\n",
        "\n",
        "    \"\"\"Computing the final covariance matrix\"\"\"\n",
        "    c = 0\n",
        "    t = []\n",
        "    cov = []\n",
        "    for i in range(0,16):\n",
        "        c += 1\n",
        "        t.append(((float(c1)/total_len)*cc1.item(i)+(float(c2)/total_len)*cc2.item(i)+(float(c3)/total_len)*cc3.item(i)))\n",
        "        if c == 4:\n",
        "            cov.append(t)\n",
        "            t = []\n",
        "            c = 0\n",
        "    cov_mat = np.matrix(cov)\n",
        "    \n",
        "    \"\"\"Inverse of the covariance matrix\"\"\"\n",
        "    cov_mat_inv = cov_mat.I\n",
        "    \n",
        "    \"\"\"Create a matrix with the values of the feature vector to be classified\"\"\"\n",
        "    ip = []\n",
        "    ip.append([float(l[0]),float(l[1]),float(l[2]),float(l[3])])\n",
        "    ip_mat = np.matrix(ip)\n",
        "\n",
        "    \"\"\"Now we use the discriminant function to calculate the probability of P(x|y)\"\"\"\n",
        "    \n",
        "    a1 = (ip_mat - mean1) * cov_mat_inv * ((ip_mat.T - mean1.T))\n",
        "    a2 = (ip_mat - mean2) * cov_mat_inv * ((ip_mat.T - mean2.T))\n",
        "    a3 = (ip_mat - mean3) * cov_mat_inv * ((ip_mat.T - mean3.T))\n",
        "    \n",
        "    cons1 = 1.0 / (math.pow(2*(22.0/7.0),c1/2) * math.pow(np.linalg.det(cov_mat),0.5))\n",
        "    cons2 = 1.0 / (math.pow(2*(22.0/7.0),c2/2) * math.pow(np.linalg.det(cov_mat),0.5))\n",
        "    cons3 = 1.0 / (math.pow(2*(22.0/7.0),c3/2) * math.pow(np.linalg.det(cov_mat),0.5))\n",
        "\n",
        "    prob1 = (float(c1)/total_len) * cons1 * math.exp(-0.5 * a1.item(0))\n",
        "    prob2 = (float(c2)/total_len) * cons2 * math.exp(-0.5 * a2.item(0))\n",
        "    prob3 = (float(c3)/total_len) * cons3 * math.exp(-0.5 * a3.item(0))    \n",
        "    \n",
        "    print (str(math.log(prob1,2)) + \"  \" + str(math.log(prob2,2)) + \"  \" + str(math.log(prob3,2)))\n",
        "    \n",
        "    if prob1 > prob2 and prob1 > prob3:\n",
        "        return 'Iris-setosa'\n",
        "    if prob2 > prob1 and prob2 > prob3:\n",
        "        return 'Iris-versicolor'\n",
        "    else:\n",
        "        return 'Iris-virginica'\n",
        "    \n",
        "def main():\n",
        "        correct = 0\n",
        "        training_file = '/content/iris.csv'\n",
        "        (listx1,listx2,listx3,c1,c2,c3,total_len) = read_training_file(training_file)\n",
        "        lines = read_testing_file(training_file)\n",
        "        print (\"The log to the base 2 probabilities of class 1, 2 and 3\")\n",
        "        for l in lines:\n",
        "          if lda(l,listx1,listx2,listx3,c1,c2,c3,total_len) == l[4]:\n",
        "            correct += 1\n",
        "\n",
        "        print (\"Classified %d correctly out of %d for a accuracy of %f\" % (correct, len(lines), float(correct)/len(lines)))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tmain()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The log to the base 2 probabilities of class 1, 2 and 3\n",
            "-60.87040706699516  -133.7544278350542  -202.4897779922196\n",
            "-62.07737237560326  -120.44671947027635  -185.65230552863667\n",
            "-61.0298236064433  -125.16841074549481  -191.5712237038119\n",
            "-62.13254700240819  -116.3560757306942  -179.54981677032922\n",
            "-61.12086525159814  -135.30789566780913  -204.08702651420782\n",
            "-62.127062960944734  -131.57153577049905  -196.11682020593602\n",
            "-61.64127813833224  -122.78469258908787  -186.46485521420058\n",
            "-60.72529714723885  -126.85748025260686  -193.49342401258048\n",
            "-63.407855070638895  -113.61737071776622  -175.94129552748853\n",
            "-61.63844218952955  -122.87115668727007  -189.6573642900222\n",
            "-61.85502495176622  -139.8958624342162  -209.97400891452844\n",
            "-61.687130135444065  -122.37048522627298  -186.9508032782881\n",
            "-61.89553614670334  -122.70285447790177  -189.6089867264427\n",
            "-62.345905845033904  -126.92886825429422  -194.79909660113537\n",
            "-68.5408867601354  -167.98004086389076  -244.82938662901245\n",
            "-68.10937027068853  -159.53776188301003  -230.30512155346682\n",
            "-63.93737516743953  -146.03473096929173  -215.01867749068975\n",
            "-60.92401481656822  -130.2272607148696  -196.78908458862023\n",
            "-62.53519238646074  -136.54303768408533  -204.16402790017204\n",
            "-61.78858303708514  -135.26604803146486  -202.26848873112738\n",
            "-61.390072400118655  -125.76702854226691  -192.07556163219652\n",
            "-61.41901258660166  -128.8698894298395  -193.18204306361986\n",
            "-62.38929502503098  -144.65799390061062  -215.98386646003394\n",
            "-62.67367241991999  -110.43407977171421  -168.28633294922977\n",
            "-64.52326203769962  -115.71695488430518  -176.96827637184947\n",
            "-62.33261065221507  -115.51831988397156  -178.97755499258542\n",
            "-61.26604124811736  -117.07345386589564  -178.2526795375495\n",
            "-60.900614238863426  -131.76421789208027  -199.86288262098955\n",
            "-61.15158846391519  -132.73259958382226  -201.4241690517544\n",
            "-62.06290164493768  -116.7118265397658  -179.78564293361205\n",
            "-61.91068174092563  -115.25659698760178  -178.28663269221477\n",
            "-62.71322961560363  -126.25507751438559  -190.4358890804662\n",
            "-66.63966006243274  -155.75891827371282  -229.13167398084104\n",
            "-66.58838097056213  -161.16430924124023  -235.40890524861373\n",
            "-61.63844218952955  -122.87115668727007  -189.6573642900222\n",
            "-61.87820925922202  -132.60842804604485  -201.5398468055546\n",
            "-63.550298562305365  -144.16875461136806  -215.9056906629602\n",
            "-61.63844218952955  -122.87115668727007  -189.6573642900222\n",
            "-62.495591606371384  -118.31414128295746  -182.26449239663748\n",
            "-60.739717455864735  -128.01470419446505  -195.1236280476728\n",
            "-61.08550806955155  -132.4091710826951  -199.60768038470192\n",
            "-72.20474713454395  -108.46463260491483  -167.09711205114257\n",
            "-62.11017329075903  -122.82034953011365  -187.80422220872836\n",
            "-63.38174418082877  -114.47342034047605  -171.82235422776782\n",
            "-63.20543360601752  -120.44924073834177  -180.83949306862843\n",
            "-62.50771691489192  -116.15348550657508  -178.7125651882865\n",
            "-62.54901554529275  -136.44403466135563  -204.51033612294262\n",
            "-61.48948743156172  -121.32205018930645  -186.14221753289914\n",
            "-61.60106132063668  -138.49909516985437  -208.10426155693253\n",
            "-60.80253829485886  -127.65212886691705  -194.8809773659136\n",
            "-124.44364604332522  -64.34791287509638  -77.81832484615185\n",
            "-126.17179846210597  -61.96491012087463  -72.64324629209118\n",
            "-136.84862665486276  -63.257060206110765  -71.34487397506943\n",
            "-135.93262746771887  -62.40584037482597  -74.07188883900996\n",
            "-138.3116180743842  -62.30105949277364  -70.27566710586454\n",
            "-137.53341502530066  -62.705197865421404  -72.35268282095912\n",
            "-135.86798568175644  -63.05689062277046  -69.38615015682495\n",
            "-109.82128445165144  -64.76835868654312  -88.40152487446595\n",
            "-127.45211124262991  -62.191719315151154  -75.50312037077305\n",
            "-130.4916094433253  -62.90211045458943  -74.15240100701608\n",
            "-125.18885943851097  -65.16904268494898  -84.98881479325587\n",
            "-126.94120971908315  -61.61833889314515  -72.22724959772718\n",
            "-124.6240413355634  -65.10778373672065  -85.14255073485211\n",
            "-139.61959685514174  -61.9011911436694  -69.56449992821565\n",
            "-108.4613992982731  -63.405178519215966  -83.08343385739943\n",
            "-119.87875929298961  -63.398464187902995  -78.26217166125956\n",
            "-142.3184893089589  -64.07754533910062  -69.93851919950946\n",
            "-115.66442272393728  -62.92840351747679  -83.49134871998659\n",
            "-157.87925469271863  -66.92862627118005  -71.49339443125461\n",
            "-118.84308597783041  -61.675499568528075  -80.3047677792007\n",
            "-157.1570435686972  -67.00415020780808  -65.46801049813895\n",
            "-116.45734322054462  -62.01644433396686  -79.10417726989243\n",
            "-159.37320481943786  -64.2499368829865  -66.39930539773621\n",
            "-136.1365498966099  -63.1338806432685  -74.62748121217687\n",
            "-119.92612970718754  -61.86979275746759  -77.56423019109208\n",
            "-122.72145727156888  -62.65254525186567  -76.52651184952073\n",
            "-138.71903577281753  -63.391221464512554  -72.73896459774001\n",
            "-152.7404438985575  -64.09268641436692  -65.26106112607022\n",
            "-137.47992332581453  -61.364380607501175  -68.60051405837912\n",
            "-102.1314242529236  -64.7861126202933  -91.01731007604326\n",
            "-119.64205057785345  -62.04906800200901  -80.79826085847041\n",
            "-113.7725640541201  -62.923577096107756  -84.95596175747418\n",
            "-115.00647181896737  -61.435344369140545  -79.8705680478014\n",
            "-170.425784535826  -66.85851589653973  -64.22960837012651\n",
            "-146.82579810555893  -66.29924686923606  -71.21426054317666\n",
            "-131.97624638407265  -64.50899520292297  -72.15540628272304\n",
            "-131.95608622388536  -62.405354004817724  -71.76653863028871\n",
            "-141.5669780534941  -64.52973703416176  -75.54096415825758\n",
            "-120.65792465369758  -62.23141341565239  -76.87810192885183\n",
            "-130.036201810166  -61.401041280041674  -74.1006113091604\n",
            "-138.7186337731266  -63.45717840184632  -74.40837341088606\n",
            "-133.71084074024185  -61.60146905822822  -70.89120414673212\n",
            "-120.33768544807144  -61.15752396878589  -77.9663213434891\n",
            "-111.03284462183632  -64.67690920857605  -88.26629470726563\n",
            "-130.14489873111458  -61.21772690084211  -73.20446754514916\n",
            "-119.62467603678228  -62.75852255365256  -78.94205192201059\n",
            "-124.30208104042477  -61.40933940615314  -74.90258170862904\n",
            "-121.38806415525096  -61.0461199390664  -75.79459718622263\n",
            "-102.08243634775427  -67.6698185049606  -93.92117594287511\n",
            "-123.09539154774663  -60.92005738016523  -75.00620442166405\n",
            "-242.01409789430383  -95.85415928253124  -68.19603048647942\n",
            "-189.09401736463516  -72.4988168496114  -62.40337028648571\n",
            "-204.10217822373144  -77.23354906076943  -61.612749318337706\n",
            "-191.32524380174397  -73.10035914503557  -63.02853328897858\n",
            "-215.49892788701777  -81.35592280297874  -61.83338173921783\n",
            "-230.43124656246198  -87.13409032914025  -66.11053240244718\n",
            "-179.0531385563552  -73.42195300743425  -69.04120973603789\n",
            "-208.57129426303658  -79.63190070212987  -66.52221712798215\n",
            "-206.1326352375411  -76.36927049207588  -63.902990836105346\n",
            "-219.75293113390592  -88.0524443173024  -65.09175318626949\n",
            "-168.95995341051207  -69.01266986527814  -62.63836158371342\n",
            "-186.86029068997445  -70.79547047819558  -61.318573431494066\n",
            "-191.63616056538172  -73.99200349502064  -61.39092555884768\n",
            "-199.322185107378  -76.27500027467025  -63.60919129145122\n",
            "-220.53464798875063  -88.48138640632298  -68.03506920859093\n",
            "-197.2236849293492  -79.06483164546113  -63.477633377437485\n",
            "-179.94200960947157  -69.6117662486865  -62.1123268830554\n",
            "-217.91509754189522  -88.58325557504777  -68.88357219642279\n",
            "-272.21520720965094  -103.6263895002858  -73.33271940565703\n",
            "-177.6006118988288  -68.54827247045327  -66.61875283660822\n",
            "-205.02762885796187  -79.92991074793744  -62.2689508601233\n",
            "-187.97038628307556  -74.28105840936273  -63.80221720180196\n",
            "-236.33886292158405  -89.71043788040919  -69.19019924393997\n",
            "-167.58959392243267  -66.61562793947697  -63.27793916891717\n",
            "-193.02824564686404  -75.25228329127455  -61.50917656628902\n",
            "-186.68442075216336  -73.42932564640061  -64.72594089089172\n",
            "-162.20856458473833  -65.70082899800904  -63.516586438172794\n",
            "-161.75215781883227  -65.83002441356474  -63.09665780393883\n",
            "-208.20705598886454  -77.93683707473127  -61.3006516791968\n",
            "-175.15914731711794  -70.50041688425077  -67.32989417361719\n",
            "-205.46318360677898  -77.96644702411173  -64.85878752029657\n",
            "-190.74075047613735  -80.34572775949317  -69.26805369863676\n",
            "-214.71242866470357  -80.86143488081271  -62.05172320186349\n",
            "-158.6191378090279  -64.50686822058042  -65.98718803975169\n",
            "-189.67247537594983  -76.1476430876545  -72.27367983138616\n",
            "-219.95091771668436  -86.45111911745202  -67.10181632461499\n",
            "-213.35956936218273  -85.87910189384988  -65.34992224964127\n",
            "-179.48153569476668  -70.45430198213356  -62.99864330573572\n",
            "-159.66810874518222  -65.76639245475687  -63.669711273387115\n",
            "-183.76042566697743  -72.86810625930738  -62.36643472032619\n",
            "-214.35678014775175  -84.11008736819537  -63.922545749521134\n",
            "-188.85615686694987  -80.29194996398796  -68.7722224226481\n",
            "-189.09401736463516  -72.4988168496114  -62.40337028648571\n",
            "-214.98786422429052  -82.42090098488491  -62.06762996085608\n",
            "-219.69151012878484  -87.59244829416484  -65.15523643552032\n",
            "-196.47951412723003  -80.02066592834477  -65.92855189657902\n",
            "-184.01476251154688  -71.40517434799057  -63.750772207591005\n",
            "-178.06938112041698  -70.06725026434  -61.54975489635025\n",
            "-200.07595039604757  -81.35989566038899  -64.75059324934156\n",
            "-173.9951810283553  -69.46099886047426  -63.56234102139957\n",
            "Classified 147 correctly out of 150 for a accuracy of 0.980000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF08XjK2vlIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}